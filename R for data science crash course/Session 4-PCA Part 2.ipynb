{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "# Written by Josue Barnes\n",
    "\n",
    "\n",
    "\n",
    "Let’s say you have a data set with 15 features (imagine columns of these features) and you are having a hard time understanding how features correlate. Or maybe you are having trouble running algorithms on your dataset because you have too many features and it is time consuming to run. Or, you want to visualize your dataset set but recognize we are limited to viewing only 3 dimensions at given time. These are all examples of the curse of dimensionality. Having a large number of features that describe a sample are great, until we have to make sense of it all. \n",
    "\n",
    "So what can we do to manage high dimensionality of datasets? One of the easiest methods to employ is reducing the number of dimensions in our dataset (aka dimensionality reduction). Two common methods for dimensionality reduction include Principal Component Analysis (PCA) and t-Distribution Stochastic Neighbor Embedding (t-SNE). \n",
    "\n",
    "Today we are going to implement PCA so visualize the iris the iris data set, which contains iris flower data. Can someone describe the data set to me? It’s size, what features we have.\n",
    "\n",
    "I want to note that I will not be diving into the math behind PCA. Simply its usefullness for dimensionality reduction and visualization. If you are interested in the math check out the following link: https://tgmstat.wordpress.com/2013/11/21/introduction-to-principal-component-analysis-pca/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species | \n",
       "|---|---|---|---|---|---|\n",
       "| 5.1    | 3.5    | 1.4    | 0.2    | setosa | \n",
       "| 4.9    | 3.0    | 1.4    | 0.2    | setosa | \n",
       "| 4.7    | 3.2    | 1.3    | 0.2    | setosa | \n",
       "| 4.6    | 3.1    | 1.5    | 0.2    | setosa | \n",
       "| 5.0    | 3.6    | 1.4    | 0.2    | setosa | \n",
       "| 5.4    | 3.9    | 1.7    | 0.4    | setosa | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the data\n",
    "data(iris) \n",
    "\n",
    "#view features\n",
    "head(iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consists of 4 continuous features and a class feature. Let’s make a variable containing our 4 continuous features of sepal.length, sepla.width, petal.length, and petal.width and one variable with the species of each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data = iris[,1:4]\n",
    "iris.species = iris[,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply PCA using the prcomp() function in R and let's save this to a variable so that we can take a look at summary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                          PC1     PC2    PC3     PC4\n",
       "Standard deviation     2.0563 0.49262 0.2797 0.15439\n",
       "Proportion of Variance 0.9246 0.05307 0.0171 0.00521\n",
       "Cumulative Proportion  0.9246 0.97769 0.9948 1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris.pca = prcomp(iris.data)\n",
    "summary(iris.pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've performed out dimensionality reduction, but what we want to pay close attention to is which PCs give us the most information by having the largest variance. First lets look at the proportion of variance. PC1 has 92% of the variance, PC2 has 5%, and PC3 1%. When looking at the cumulative proportion we will want to use enough PC's so that this proportion is about 90%. This isn't a fixed number, it is very much up to the user to decide which principal components are most useful. In this case PC1 and PC2 give us what we need.\n",
    "\n",
    "Now let's plot PC1 against PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(data = iris.pca, aes(PC1, PC2, col = iris.species)): could not find function \"ggplot\"\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(data = iris.pca, aes(PC1, PC2, col = iris.species)): could not find function \"ggplot\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "ggplot(data=iris.pca, aes(PC1,PC2, col=iris.species)) + geom_point(size=3.5) + theme_linedraw() +\n",
    "geom_smooth(method = \"lm\", se = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully what you see are 3 clusters, each representing a species of iris. The data has been transformed into a linear combination that maximizes the varaince."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
